{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ebay Web Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "useful links for info info on parsing html and the libraries/functions used here:  \n",
    "https://www.w3schools.com/xml/xpath_syntax.asp   - xPath syntax - find nodes in xml/html  \n",
    "https://lxml.de/lxmlhtml.html - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "questions, comments, ect:  \n",
    "    -how are headers used, how would I change them\n",
    "    -What is the HTML get request object?\n",
    "        -what is the object created by html.fromstring from this?\n",
    "    -where does xpath come from?\n",
    "    -why does \"\"\"if __name__==\"__main__\":\"\"\" return true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse #allows for command line arguments insertion\n",
    "from pprint import pprint #not used???\n",
    "from traceback import format_exc \n",
    "\n",
    "import requests\n",
    "import unicodecsv as csv\n",
    "from lxml import html\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image #not stricktly necesarry for scraping\n",
    "from io import BytesIO # see above comment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**parse** function takes the *brand* (search query) argument, creates a html get request with ebay url formula, then useds xpath to sort through the page and first find listings - then price, product url, and title from within the listings. Each listing is written to a dictionary with it's info, and the dictionary then appended to the list of listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(brand):\n",
    "\n",
    "    url = 'https://www.ebay.com/sch/i.html?_nkw={0}&_sacat=0'.format(brand)\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36'}\n",
    "    failed = False\n",
    "\n",
    "    # Retries for handling network errors\n",
    "    for _ in range(5):\n",
    "        print (\"Retrieving %s\"%(url))\n",
    "        response = requests.get(url, headers=headers, verify=False) #use requests to send a html get request - scrape the ebay page\n",
    "        parser = html.fromstring(response.text) \n",
    "        print (\"Parsing page\")\n",
    "\n",
    "        if response.status_code!=200:\n",
    "            failed = True\n",
    "            continue\n",
    "        else:\n",
    "            failed = False\n",
    "            break\n",
    "\n",
    "    if failed:\n",
    "        return []\n",
    "\n",
    "    product_listings = parser.xpath('//li[contains(@id,\"results-listing\")]') #use xpath to find all listing nodes\n",
    "    raw_result_count = parser.xpath(\"//h1[contains(@class,'count-heading')]//text()\")\n",
    "    result_count = ''.join(raw_result_count).strip()\n",
    "    print (\"Found {0} for {1}\".format(result_count,brand))\n",
    "    scraped_products = []\n",
    "\n",
    "    for product in product_listings:\n",
    "        raw_url = product.xpath('.//a[contains(@class,\"item__link\")]/@href')\n",
    "        raw_title = product.xpath('.//h3[contains(@class,\"item__title\")]//text()')\n",
    "        raw_product_type = product.xpath('.//h3[contains(@class,\"item__title\")]/span[@class=\"LIGHT_HIGHLIGHT\"]/text()')\n",
    "        raw_price = product.xpath('.//span[contains(@class,\"s-item__price\")]//text()')\n",
    "        price  = ' '.join(' '.join(raw_price).split())\n",
    "        title = ' '.join(' '.join(raw_title).split())\n",
    "        product_type = ''.join(raw_product_type)\n",
    "        title = title.replace(product_type, '').strip()\n",
    "        data = {\n",
    "                    'url':raw_url[0],\n",
    "                    'title':title,\n",
    "                    'price':price\n",
    "        }\n",
    "        scraped_products.append(data)\n",
    "    return scraped_products\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the argparser stuff allows for command line arguments (ie. >python scrape bn94*** from cl)  \n",
    "Takes data list and writes it to a csv file named '''arg-ebay-scraped-data.csv'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\": #this returns true, but idk why\n",
    "\n",
    "    argparser = argparse.ArgumentParser()\n",
    "    argparser.add_argument('brand',help = 'Brand Name')\n",
    "    args = argparser.parse_args()\n",
    "    brand = args.brand\n",
    "\n",
    "    scraped_data =  parse(brand)\n",
    "    if scraped_data: # if data scrape successful\n",
    "        print (\"Writing scraped data to %s-ebay-scraped-data.csv\"%(brand)) #output log\n",
    "        with open('%s-ebay-scraped-data.csv'%(brand),'wb') as csvfile: #open csv file to be written to in binary\n",
    "            fieldnames = [\"title\",\"price\",\"url\"] #collumns\n",
    "            writer = csv.DictWriter(csvfile,fieldnames = fieldnames,quoting=csv.QUOTE_ALL)\n",
    "            writer.writeheader()\n",
    "            for data in scraped_data:\n",
    "                writer.writerow(data)\n",
    "    else:\n",
    "        print(\"No data scraped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving https://www.ebay.com/sch/i.html?_nkw=bn94&_sacat=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing page\n",
      "Found 21,310 results for bn94\n"
     ]
    }
   ],
   "source": [
    "data = parse('bn94')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            $51.90\n",
       "1           $105.00\n",
       "2            $30.00\n",
       "3            $22.50\n",
       "4            $57.99\n",
       "5            $29.99\n",
       "6            $50.00\n",
       "7            $80.33\n",
       "8            $29.95\n",
       "9            $51.90\n",
       "10           $38.99\n",
       "11           $73.50\n",
       "12           $49.00\n",
       "13           $22.84\n",
       "14          $199.90\n",
       "15          $199.90\n",
       "16           $60.00\n",
       "17           $29.99\n",
       "18           $30.00\n",
       "19           $27.00\n",
       "20            $9.84\n",
       "21           $27.99\n",
       "22           $99.99\n",
       "23          $199.90\n",
       "24           $46.50\n",
       "25           $29.95\n",
       "26           $34.00\n",
       "27           $27.00\n",
       "28           $19.99\n",
       "29          $100.00\n",
       "          ...      \n",
       "31           $49.00\n",
       "32           $40.00\n",
       "33           $41.00\n",
       "34           $42.00\n",
       "35           $46.50\n",
       "36    $19.00 $32.00\n",
       "37           $25.00\n",
       "38           $57.90\n",
       "39          $129.90\n",
       "40           $80.95\n",
       "41           $38.99\n",
       "42           $21.00\n",
       "43           $48.00\n",
       "44           $29.95\n",
       "45           $34.00\n",
       "46           $46.00\n",
       "47           $26.99\n",
       "48           $64.90\n",
       "49           $16.99\n",
       "50           $18.00\n",
       "51           $20.76\n",
       "52           $89.95\n",
       "53           $65.00\n",
       "54           $69.95\n",
       "55           $39.95\n",
       "56           $29.99\n",
       "57           $18.95\n",
       "58           $39.95\n",
       "59          $140.90\n",
       "60          $130.90\n",
       "Name: price, Length: 61, dtype: object"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=data)['price']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['$', 'S', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'S', 'h'],\n",
       "       ['$', 'S', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['T', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['T', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['T', 'S', 'h'],\n",
       "       ['T', 'S', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['T', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['T', 'A', 'h'],\n",
       "       ['$', 'S', 'h'],\n",
       "       ['$', 'S', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['T', 'S', 'h'],\n",
       "       ['T', 'S', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['$', 'A', 'h'],\n",
       "       ['T', 'S', 'h'],\n",
       "       ['T', 'S', 'h']], dtype='<U1')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make an array instead\n",
    "if __name__==\"__main__\": #this returns true, but idk why\n",
    "\n",
    "    argparser = argparse.ArgumentParser()\n",
    "    argparser.add_argument('brand',help = 'Brand Name')\n",
    "    args = argparser.parse_args()\n",
    "    brand = args.brand\n",
    "\n",
    "    scraped_data =  parse(brand)\n",
    "    if scraped_data: # if data scrape successful\n",
    "        print (\"Writing scraped data to %s-ebay-scraped-data.csv\"%(brand)) #output log\n",
    "        \n",
    "        with open('%s-ebay-scraped-data.csv'%(brand),'wb') as csvfile: #open csv file to be written to in binary\n",
    "            fieldnames = [\"title\",\"price\",\"url\"] #collumns\n",
    "            writer = csv.DictWriter(csvfile,fieldnames = fieldnames,quoting=csv.QUOTE_ALL)\n",
    "            writer.writeheader()\n",
    "            for data in scraped_data:\n",
    "                writer.writerow(data)\n",
    "    else:\n",
    "        print(\"No data scraped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    }
   ],
   "source": [
    "brand= 'iphone'\n",
    "url = 'https://www.ebay.com/sch/i.html?_nkw={0}&_sacat=0'.format(brand) #construct url using simple ebay base url\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36'} #not sure\n",
    "\n",
    "req = requests.get(url, verify=False) ## create html request object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.ebay.com/itm/Apple-iPhone-6s-Factory-Unlocked-AT-T-Verizon-T-Mobile-Sprint-LTE-GSM-MORE/322120351037?epid=216192462&_trkparms=ispr%3D1&hash=item4affde7d3d:m:mIMqzKfEHk3O3upZJerMH8A&enc=AQADAAAB0KX%2FKt4E1xf3SDqEdBclaYa6EEWZ5R%2Bo701PpO3uApHxry1Qe32gK1Sk7ze9%2BhkvgEfoWV9xG45XaRppF95VjbF9%2FydUsCTnp%2BOdHsks2OEQ03yRAHx35lywQzRr1zxcwhNTQYzm1RHnw85ckke7kndlFpRdy0gJkXEwUcBtQwJreE%2F41G%2BLLlDwd5VyzCmMXmhOnE4jIVzhZBXWOYoKbS%2FudwI37K0BRrX6U7UuETjVb7bTAy2w9HBPCMWgpSs2B4VBQ3B5O3s8jQBa42RDlPGjelg2Xl0VDamt%2Bd8K56z6MgORWqcmDxsXGeiJ%2BvnqyS6V00ktlGdNmdy%2By8ZASuP24jWvZmwl2%2Fb28%2Beui0vRL00fbvAHduetT7vfKbzUgcz%2BTCaRuYTzm%2FoGpF5zLI7Fu3qemmj1Bks1axFjr6lOOmCkmdMEHcybzLQ440AuPmwtKiy4VLXFxuO%2F69l2zXNo0lY5SDM9osU%2BYzHgz4iQPpHdESIIouumC1mrJNP2TWkcpckhcuVwyh4uJtsdAD0KQ%2B2d3Rs3KlReSyNxb2C4b5rZUtz4kom16J%2Bwd8yn%2B64t814Zf1GljwE6VmmE9xYds18LE0bkdldPcFv127n2&checksum=322120351037380d4d428746436cab47d7a2271b9fde']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#req.status_code\n",
    "#req.encoding\n",
    "#req.text #get text from request - using encoding specified by req.encoding\n",
    "#req.content \n",
    "#i = Image.open(BytesIO(req.content)\n",
    "#parser =\n",
    "html.fromstring(req.text).xpath('//li[contains(@id,\"results-listing\")]')[0].xpath('.//a[contains(@class,\"item__link\")]/@href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element html at 0x1cd94562368>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
